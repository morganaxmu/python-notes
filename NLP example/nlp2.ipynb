{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop a Neural Bag-of-Words Model for Sentiment Analysis\n",
    "Movie reviews can be classified as either favorable or not. The evaluation of movie review text is a classification problem often called sentiment analysis. A popular technique for developing sentiment analysis models is to use a bag-of-words model that transforms documents into vectors where each word in the document is assigned a score. In this workshop, you will learn how you can develop a deep learning predictive model using the bag-of-words representation for movie review sentiment classification. After completing this tutorial, you will know:\n",
    "- How to prepare the review text data for modeling with a restricted vocabulary.\n",
    "- How to use the bag-of-words model to prepare train and test data.\n",
    "- How to develop a Multilayer Perceptron bag-of-words model and use it to make predictions on new review text data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie Review Dataset\n",
    "In this workshop, we will use the Movie Review Dataset. You can download the dataset from here:\n",
    "- Movie Review Polarity Dataset (`review_polarity.tar.gz`, 3MB)\n",
    "http://www.cs.cornell.edu/people/pabo/movie-review-data/review_polarity.tar.gz\n",
    "\n",
    "After unzipping the file, you will have a directory called `txt_sentoken` with two subdirectories containing the text neg and pos or negative and positive reviews. Reviews are stored one per file with a naming convention `cv000` to `cv999` for each of neg and pos.\n",
    "\n",
    "Please ensure that the txt_sentoken directory is in the same directory as this jupyter notebook, otherwise you will have to change the filenames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "we will look at 3 things:\n",
    "- Separation of data into training and test sets.\n",
    "- Loading and cleaning the data to remove punctuation and numbers.\n",
    "- Defining a vocabulary of preferred words.\n",
    "\n",
    "### Split into Train and TestSets\n",
    "We are developing a system that can predict the sentiment of a textual movie review as either positive or negative. This means that after the model is developed, we will need to make predictions on new textual reviews. This will require all of the same data preparation to be performed on those new reviews as is performed on the training data for the model.\n",
    "\n",
    "We will ensure that this constraint is built into the evaluation of our models by splitting the main data set to training and test sets prior to any data preparation. This means that any knowledge in the test set that could help us better prepare the data (e.g. the words used) is unavailable during the preparation of data and the training of the model. That being said, we will use the last 100 positive reviews and the last 100 negative reviews as a test set and the remaining 1,800 reviews as the training dataset. This is a 90% train, 10% split of the data. The split can be imposed easily by using the filenames of the reviews where reviews named 000 to 899 are for training data and reviews named 900 onwards are for testing the model.\n",
    "### Loading and Cleaning Reviews\n",
    "we will prepare the data using the following steps:\n",
    "- Split tokens using white space.\n",
    "- Remove all punctuation from words.\n",
    "- Remove all words that are not purely comprised of alphabetical characters.\n",
    "- Remove all words that are stop words.\n",
    "- Remove all words that have a length â‰¤ 1 character.\n",
    "\n",
    "We can put all of these steps into a function called `clean_doc()` that takes as an argument the raw text loaded from a file and returns a list of cleaned tokens. We can also define a function `load_doc()` that loads a document from file ready for use with the `clean_doc()` function. An example of cleaning the first positive review is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\billy\n",
      "[nltk_data]     huang\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename, 'r')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn a doc into clean tokens\n",
    "def clean_doc(doc):\n",
    "    # split into tokens by white space\n",
    "    tokens = doc.split()\n",
    "    # prepare regex for char filtering\n",
    "    re_punc = re.compile(f\"[{re.escape(string.punctuation)}]\")\n",
    "    # remove punctuation from each word\n",
    "    tokens = [re_punc.sub('', w) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    # filter out short tokens\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "re.compile('[!\"\\\\#\\\\$%\\\\&\\'\\\\(\\\\)\\\\*\\\\+,\\\\-\\\\./:;<=>\\\\?@\\\\[\\\\\\\\\\\\]\\\\^_`\\\\{\\\\|\\\\}\\\\~]')\n",
      "['films', 'adapted', 'from', 'comic', 'books']\n",
      "['films', 'adapted', 'comic', 'books', 'plenty', 'success', 'whether', 'theyre', 'superheroes', 'batman', 'superman', 'spawn', 'geared', 'toward', 'kids', 'casper', 'arthouse', 'crowd', 'ghost', 'world', 'theres', 'never', 'really', 'comic', 'book', 'like', 'hell', 'starters', 'created', 'alan', 'moore', 'eddie', 'campbell', 'brought', 'medium', 'whole', 'new', 'level', 'mid', 'series', 'called', 'watchmen', 'say', 'moore', 'campbell', 'thoroughly', 'researched', 'subject', 'jack', 'ripper', 'would', 'like', 'saying', 'michael', 'jackson', 'starting', 'look', 'little', 'odd', 'book', 'graphic', 'novel', 'pages', 'long', 'includes', 'nearly', 'consist', 'nothing', 'footnotes', 'words', 'dont', 'dismiss', 'film', 'source', 'get', 'past', 'whole', 'comic', 'book', 'thing', 'might', 'find', 'another', 'stumbling', 'block', 'hells', 'directors', 'albert', 'allen', 'hughes', 'getting', 'hughes', 'brothers', 'direct', 'seems', 'almost', 'ludicrous', 'casting', 'carrot', 'top', 'well', 'anything', 'riddle', 'better', 'direct', 'film', 'thats', 'set', 'ghetto', 'features', 'really', 'violent', 'street', 'crime', 'mad', 'geniuses', 'behind', 'menace', 'ii', 'society', 'ghetto', 'question', 'course', 'whitechapel', 'londons', 'east', 'end', 'filthy', 'sooty', 'place', 'whores', 'called', 'unfortunates', 'starting', 'get', 'little', 'nervous', 'mysterious', 'psychopath', 'carving', 'profession', 'surgical', 'precision', 'first', 'stiff', 'turns', 'copper', 'peter', 'godley', 'robbie', 'coltrane', 'world', 'enough', 'calls', 'inspector', 'frederick', 'abberline', 'johnny', 'depp', 'blow', 'crack', 'case', 'abberline', 'widower', 'prophetic', 'dreams', 'unsuccessfully', 'tries', 'quell', 'copious', 'amounts', 'absinthe', 'opium', 'upon', 'arriving', 'whitechapel', 'befriends', 'unfortunate', 'named', 'mary', 'kelly', 'heather', 'graham', 'say', 'isnt', 'proceeds', 'investigate', 'horribly', 'gruesome', 'crimes', 'even', 'police', 'surgeon', 'cant', 'stomach', 'dont', 'think', 'anyone', 'needs', 'briefed', 'jack', 'ripper', 'wont', 'go', 'particulars', 'say', 'moore', 'campbell', 'unique', 'interesting', 'theory', 'identity', 'killer', 'reasons', 'chooses', 'slay', 'comic', 'dont', 'bother', 'cloaking', 'identity', 'ripper', 'screenwriters', 'terry', 'hayes', 'vertical', 'limit', 'rafael', 'yglesias', 'les', 'mis', 'rables', 'good', 'job', 'keeping', 'hidden', 'viewers', 'end', 'funny', 'watch', 'locals', 'blindly', 'point', 'finger', 'blame', 'jews', 'indians', 'englishman', 'could', 'never', 'capable', 'committing', 'ghastly', 'acts', 'hells', 'ending', 'whistling', 'stonecutters', 'song', 'simpsons', 'days', 'holds', 'back', 'electric', 'carwho', 'made', 'steve', 'guttenberg', 'star', 'dont', 'worry', 'itll', 'make', 'sense', 'see', 'onto', 'hells', 'appearance', 'certainly', 'dark', 'bleak', 'enough', 'surprising', 'see', 'much', 'looks', 'like', 'tim', 'burton', 'film', 'planet', 'apes', 'times', 'seems', 'like', 'sleepy', 'hollow', 'print', 'saw', 'wasnt', 'completely', 'finished', 'color', 'music', 'finalized', 'comments', 'marilyn', 'manson', 'cinematographer', 'peter', 'deming', 'dont', 'say', 'word', 'ably', 'captures', 'dreariness', 'victorianera', 'london', 'helped', 'make', 'flashy', 'killing', 'scenes', 'remind', 'crazy', 'flashbacks', 'twin', 'peaks', 'even', 'though', 'violence', 'film', 'pales', 'comparison', 'blackandwhite', 'comic', 'oscar', 'winner', 'martin', 'childs', 'shakespeare', 'love', 'production', 'design', 'turns', 'original', 'prague', 'surroundings', 'one', 'creepy', 'place', 'even', 'acting', 'hell', 'solid', 'dreamy', 'depp', 'turning', 'typically', 'strong', 'performance', 'deftly', 'handling', 'british', 'accent', 'ians', 'holm', 'joe', 'goulds', 'secret', 'richardson', 'dalmatians', 'log', 'great', 'supporting', 'roles', 'big', 'surprise', 'graham', 'cringed', 'first', 'time', 'opened', 'mouth', 'imagining', 'attempt', 'irish', 'accent', 'actually', 'wasnt', 'half', 'bad', 'film', 'however', 'good', 'strong', 'violencegore', 'sexuality', 'language', 'drug', 'content']\n"
     ]
    }
   ],
   "source": [
    "# load the document\n",
    "filename = 'txt_sentoken/pos/cv000_29590.txt'\n",
    "text = load_doc(filename)\n",
    "tokens = clean_doc(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The complete example can be found in `1_clean_review.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Vocabulary\n",
    "It is important to define a vocabulary of known words when using a bag-of-words model. The more words,the larger the representation of documents,therefore it is important to constrain the words to only those believed to be predictive. This is difficult to know beforehand and often it is important to test different hypotheses about how to construct a useful vocabulary. We can develop a vocabulary as a `Counter`, which is a dictionary mapping of words and their count that allows us to easily update and query. Each document can be added to the counter (a new function called `add_doc_to_vocab()`) and we can step over all of the reviews in the negative directory and then the positive directory (a new function called `process_docs()`). The complete example is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load doc and add to vocab\n",
    "def add_doc_to_vocab(filename, vocab):\n",
    "    # load doc\n",
    "    doc = load_doc(filename)\n",
    "    # clean doc\n",
    "    tokens = clean_doc(doc)\n",
    "    # update counts\n",
    "    vocab.update(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all docs in a directory\n",
    "def process_docs(directory, vocab):\n",
    "    # walk through all files in the folder\n",
    "    for filename in listdir(directory):\n",
    "        # skip any reviews in the test set\n",
    "        if filename.startswith('cv9'):\n",
    "            continue\n",
    "        # create the full path of the file to open\n",
    "        path = directory + '/' + filename\n",
    "        # add doc to vocab\n",
    "        add_doc_to_vocab(path, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define vocab\n",
    "vocab = Counter()\n",
    "# add all docs to vocab\n",
    "process_docs('txt_sentoken/pos', vocab)\n",
    "process_docs('txt_sentoken/neg', vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44276\n"
     ]
    }
   ],
   "source": [
    "# print the size of the vocab\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('film', 7983), ('one', 4946), ('movie', 4826), ('like', 3201), ('even', 2262), ('good', 2080), ('time', 2041), ('story', 1907), ('films', 1873), ('would', 1844), ('much', 1824), ('also', 1757), ('characters', 1735), ('get', 1724), ('character', 1703), ('two', 1643), ('first', 1588), ('see', 1557), ('way', 1515), ('well', 1511), ('make', 1418), ('really', 1407), ('little', 1351), ('life', 1334), ('plot', 1288), ('people', 1269), ('could', 1248), ('bad', 1248), ('scene', 1241), ('movies', 1238), ('never', 1201), ('best', 1179), ('new', 1140), ('scenes', 1135), ('man', 1131), ('many', 1130), ('doesnt', 1118), ('know', 1092), ('dont', 1086), ('hes', 1024), ('great', 1014), ('another', 992), ('action', 985), ('love', 977), ('us', 967), ('go', 952), ('director', 948), ('end', 946), ('something', 945), ('still', 936)]\n"
     ]
    }
   ],
   "source": [
    "# print the top words in the vocab\n",
    "print(vocab.most_common(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example shows that we have a vocabulary of 44,276 words. We also can see a sample of the top 50 most used words in the movie reviews. Note that this vocabulary was constructed based on only those reviews in the training dataset.\n",
    "\n",
    "The complete example can be found in `2_select_vocab.py`.\n",
    "\n",
    "We can step through the vocabulary and remove all words that have a low occurrence, such as only being used once or twice in all reviews. For example, the following snippet will retrieve only the tokens that appear 2 or more times in all reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25767\n"
     ]
    }
   ],
   "source": [
    "min_occurrence = 2\n",
    "tokens = [k for k, c in vocab.items() if c >= min_occurrence]\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the above example with this addition shows that the vocabulary size drops by a little more than half its size, from about 44,000 to about 25,000 words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the vocabulary can be saved to a new file called `vocab.txt` that we can later load and use to filter movie reviews prior to encoding them for modeling. We define a new function called save_list() that saves the vocabulary to file, with one word per line. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save list to file\n",
    "def save_list(lines, filename):\n",
    "    # convert lines to a single blob of text\n",
    "    data = '\\n'.join(lines)\n",
    "    # open file\n",
    "    file = open(filename, 'w')\n",
    "    # write text\n",
    "    file.write(data)\n",
    "    # close file\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save tokens to a vocabulary file\n",
    "save_list(tokens, 'vocab.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the min occurrence filter on the vocabulary and saving it to file, you should now have a new file called `vocab.txt` with only the words we are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing the first 10 words from the vocab.txt file:\n",
      "    films\n",
      "    adapted\n",
      "    comic\n",
      "    books\n",
      "    plenty\n",
      "    success\n",
      "    whether\n",
      "    theyre\n",
      "    superheroes\n",
      "    batman\n"
     ]
    }
   ],
   "source": [
    "N_WORDS_TO_PRINT = 10\n",
    "print(f\"Printing the first {N_WORDS_TO_PRINT} words from the vocab.txt file:\")\n",
    "with open('vocab.txt') as f:\n",
    "    for i in range(N_WORDS_TO_PRINT):\n",
    "        print(f\"    {f.readline()}\", end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The complete example can be found in `3_filter_vocab.py`.\n",
    "\n",
    "We are now ready to look at extracting features from the reviews ready for modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag-of-Words Representation\n",
    "Here we will look at how we can convert each review into a representation that we can provide to a Multilayer Perceptron model. A bag-of-words model is a way of extracting features from text so the text input can be used with machine learning algorithms like neural networks. Each document, in this case a review, is converted into a vector representation. The number of items in the vector representing a document corresponds to the number of words in the vocabulary. The larger the vocabulary, the longer the vector representation, hence the preference for smaller vocabularies in the previous section.\n",
    "\n",
    "Words in a document are scored and the scores are placed in the corresponding location in the representation. We will look at different word scoring methods in the next section. In this section, we are concerned with converting reviews into vectors ready for training a first neural network model. This section is divided into 2 steps:\n",
    "\n",
    "- Converting reviews to lines of tokens.\n",
    "- Encoding reviews with a bag-of-words model representation.\n",
    "\n",
    "### Reviews to Lines of Tokens\n",
    "Before we can convert reviews to vectors for modeling, we must first clean them up. This involves loading them, performing the cleaning operation developed above,filtering out words not in the chosen vocabulary, and converting the remaining tokens into a single string or ready for encoding. First, we need a function to prepare one document. Below is the function `doc_to_line()` that will load a document, clean it, filter out tokens not in the vocabulary, then return the document as a string of white space separated tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load doc, clean and return line of tokens\n",
    "def doc_to_line(filename, vocab):\n",
    "    # load the doc\n",
    "    doc = load_doc(filename)\n",
    "    # clean doc\n",
    "    tokens = clean_doc(doc)\n",
    "    # filter by vocab\n",
    "    tokens = [w for w in tokens if w in vocab]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need a function to work through all documents in a directory (such as `pos` and `neg`) to convert the documents into lines. Below lists the `process_docs()` function that does just this, expecting a directory name and a vocabulary set as input arguments and returning a list of processed documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all docs in a directory\n",
    "def process_docs(directory, vocab):\n",
    "    lines = list()\n",
    "    # walk through all files in the folder\n",
    "    for filename in listdir(directory):\n",
    "        # skip any reviews in the test set\n",
    "        if filename.startswith('cv9'):\n",
    "            continue\n",
    "        # create the full path of the file to open\n",
    "        path = directory + '/' + filename\n",
    "        # load and clean the doc\n",
    "        line = doc_to_line(path, vocab)\n",
    "        # add to list\n",
    "        lines.append(line)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can call the `process_docs()` consistently for positive and negative reviews to construct a dataset of review text and their associated output labels, 0 for negative and 1 for positive. The `load_clean_data()` function below implements this behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and clean a dataset\n",
    "def load_clean_dataset(vocab):\n",
    "    # load documents\n",
    "    neg = process_docs('txt_sentoken/neg', vocab)\n",
    "    pos = process_docs('txt_sentoken/pos', vocab)\n",
    "    docs = neg + pos\n",
    "    # prepare labels\n",
    "    labels = [0 for _ in range(len(neg))] + [1 for _ in range(len(pos))]\n",
    "    return docs, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to load the vocabulary and turn it into a set for use in cleaning reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the vocabulary\n",
    "vocab_filename = 'vocab.txt'\n",
    "vocab = load_doc(vocab_filename)\n",
    "vocab = vocab.split()\n",
    "vocab = set(vocab)\n",
    "# load all training reviews\n",
    "docs, labels = load_clean_dataset(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this example loads and cleans the review text and returns the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800 1800\n"
     ]
    }
   ],
   "source": [
    "# summarize what we have\n",
    "print(len(docs), len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The complete example can be found in `4_filter_all_reviews.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movie Reviews to Bat-of-Words Vectors\n",
    "We will use the Keras API to convert reviews to encoded document vectors. Keras provides the `Tokenizer` class that can do some of the cleaning and vocab definition tasks that we took care of in the previous section. The `Tokenizer` class is convenient and will easily transform documents into encoded vectors. First, the `Tokenizer` must be created, then fit on the text documents in the training dataset. In this case, these are the aggregation of the positive lines and negative lines arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a tokenizer\n",
    "def create_tokenizer(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process determines a consistent way to convert the vocabulary to a fixed-length vector with 25,768 elements, which is the total number of words in the vocabulary file `vocab.txt`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, documents are encoded using the `Tokenizer` by calling `text_to_matrix()`. The function takes both a list of documents to encode and an encoding mode, which is the method used to score words in the document. Here we specify `freq` to score words based on their frequency in the document. This can be used to encode the loaded training and test data, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = create_tokenizer(docs)\n",
    "# encode data\n",
    "Xtrain = tokenizer.texts_to_matrix(docs, mode='freq')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This encodes all of the positive and negative reviews in the training dataset. Next, the `process_doc()` function from the previous section needs to be modified to selectively process reviews in the test or train dataset. We support the loading of both the training and test datasets by adding an `is_train` argument and using that to decide what review file names to skip. By adding a default value to `is_train` we ensure backwards compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all docs in a directory\n",
    "def process_docs(directory, vocab, is_train=True):\n",
    "    lines = list()\n",
    "    # walk through all files in the folder\n",
    "    for filename in listdir(directory):\n",
    "        # skip any reviews in the test set\n",
    "        if is_train and filename.startswith('cv9'):\n",
    "            continue\n",
    "        if not is_train and not filename.startswith('cv9'):\n",
    "            continue\n",
    "        # create the full path of the file to open\n",
    "        path = directory + '/' + filename\n",
    "        # load and clean the doc\n",
    "        line = doc_to_line(path, vocab)\n",
    "        # add to list\n",
    "        lines.append(line)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, the `load_clean_dataset()` dataset must be updated to load either train or test data and ensure it returns a NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clean_dataset(vocab, is_train=True):\n",
    "    # load documents\n",
    "    neg = process_docs('txt_sentoken/neg', vocab, is_train)\n",
    "    pos = process_docs('txt_sentoken/pos', vocab, is_train)\n",
    "    docs = neg + pos\n",
    "    # prepare labels\n",
    "    labels = array([0 for _ in range(len(neg))] + [1 for _ in range(len(pos))])\n",
    "    return docs, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example prints both the shape of the encoded training dataset and test dataset with 1,800 and 200 documents respectively, each with the same sized encoding vocabulary (vector length)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all reviews\n",
    "train_docs, ytrain = load_clean_dataset(vocab, True)\n",
    "test_docs, ytest = load_clean_dataset(vocab, False)\n",
    "# create the tokenizer\n",
    "tokenizer = create_tokenizer(train_docs)\n",
    "# encode data\n",
    "Xtrain = tokenizer.texts_to_matrix(train_docs, mode='freq')\n",
    "Xtest = tokenizer.texts_to_matrix(test_docs, mode='freq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1800, 25768) (200, 25768)\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain.shape, Xtest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The complete example can be found in `5_prepare_data.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis Models\n",
    "In this section, we will develop Multilayer Perceptron (MLP) models to classify encoded documents as either positive or negative. The models will be simple feed forward network models with fully connected layers called `Dense` in the Keras deep learning library.\n",
    "### First Sentiment Analysis Model\n",
    "We can develop a simple MLP model to predict the sentiment of encoded reviews. The model will have an input layer that equals to the number of words in the vocabulary, and in turn the length of the input documents. We can store this in a new variable called `n_words`, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_words = Xtest.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now define the network. We will use a single hidden layer with 50 neurons and a rectified linear activation function. The output layer is a single neuron with a sigmoid activation function for predicting 0 for negative and 1 for positive reviews. The network will be trained using Adam implementation of gradient descent and the binary cross-entropy loss function, suited to binary classification problems. We will keep track of accuracy when training and evaluating the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "def define_model(n_words):\n",
    "    # define network\n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, input_shape=(n_words, ), activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compile network\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When defining the model, the summary of the model is printed and a plot is saved with the name `model.png`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                1288450   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 1,288,501\n",
      "Trainable params: 1,288,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "model = define_model(n_words)\n",
    "# summarize defined model\n",
    "model.summary()\n",
    "# If you get an error on the following line, you might neet to install Graphviz.\n",
    "# You could alternatively just comment it out and not generate 'model.png'.\n",
    "plot_model(model, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we fit the model on the training data; in this case, the model is small and is easily fit in 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "57/57 - 0s - loss: 0.6920 - accuracy: 0.5717\n",
      "Epoch 2/10\n",
      "57/57 - 0s - loss: 0.6842 - accuracy: 0.7767\n",
      "Epoch 3/10\n",
      "57/57 - 0s - loss: 0.6693 - accuracy: 0.8989\n",
      "Epoch 4/10\n",
      "57/57 - 0s - loss: 0.6457 - accuracy: 0.8894\n",
      "Epoch 5/10\n",
      "57/57 - 0s - loss: 0.6150 - accuracy: 0.9233\n",
      "Epoch 6/10\n",
      "57/57 - 0s - loss: 0.5782 - accuracy: 0.9339\n",
      "Epoch 7/10\n",
      "57/57 - 0s - loss: 0.5382 - accuracy: 0.9433\n",
      "Epoch 8/10\n",
      "57/57 - 0s - loss: 0.4966 - accuracy: 0.9500\n",
      "Epoch 9/10\n",
      "57/57 - 0s - loss: 0.4567 - accuracy: 0.9550\n",
      "Epoch 10/10\n",
      "57/57 - 0s - loss: 0.4173 - accuracy: 0.9633\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24f7a197e88>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit network\n",
    "model.fit(Xtrain, ytrain, epochs=10, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the model fits the training data within the 10 epochs, achieving close to 100% accuracy. \n",
    "\n",
    "Finally, once the model is trained, we can evaluate its performance by making predictions in the test dataset and printing the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 87.50%\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "loss, acc = model.evaluate(Xtest, ytest, verbose=0)\n",
    "print(f\"Test Accuracy: {acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the model on the test dataset, we can see that model does well, achieving an accuracy of above 87%.\n",
    "\n",
    "The complete example can be found in `6_mlp_bow_model.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Word Scoring Methods\n",
    "\n",
    "The `text_to_matrix()` function for the `Tokenizer` in the Keras API provides 4 different methods for scoring words; they are:\n",
    "- **binary** Where words are marked as present (1) or absent (0)\n",
    "- **count** Where the occurrence count for each word is marked as an integer.\n",
    "- **tfidf** Where each word is scored based on their frequency, where words that are common across all documents are penalized.\n",
    "- **freq** Where words are scored based on their frequency of occurrence within the document.\n",
    "\n",
    "We can evaluate the model developed in the previous section using each of the 4 supported word scoring mode. This first involves the implementation of a function to create an encoding of the loaded documents based on a chosen scoring model. The function creates the tokenizer, fits it on the training documents, then creates the train and test encodings using the chosen model. The function `prepare_data()` implements this behavior given lists of train and test documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare bag of words encoding of docs\n",
    "def prepare_data(train_docs, test_docs, mode):\n",
    "    # create the tokenizer\n",
    "    tokenizer = Tokenizer()\n",
    "    # fit the tokenizer on the documents\n",
    "    tokenizer.fit_on_texts(train_docs)\n",
    "    # encode training data set\n",
    "    Xtrain = tokenizer.texts_to_matrix(train_docs, mode=mode)\n",
    "    # encode training data set\n",
    "    Xtest = tokenizer.texts_to_matrix(test_docs, mode=mode)\n",
    "    return Xtrain, Xtest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need a function to evaluate the MLP given a specific encoding of the data. Because neural networks are stochastic, they can produce different results when the same model is fit on the same data. This is mainly because of the random initial weights and the shuffling of patterns during minibatch gradient descent. This means that any scoring of a model is unreliable and we should estimate model performance based on an average of multiple runs. The function below, named `evaluate_mode()` takes encoded documents and evaluates the MLP by training it on the train set and estimating the performance on the test set 10 times and returns a list of the accuracy scores across all of these runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a neural network model\n",
    "def evaluate_mode(Xtrain, ytrain, Xtest, ytest):\n",
    "    scores = list()\n",
    "    n_repeats = 4\n",
    "    n_words = Xtest.shape[1]\n",
    "    for i in range(n_repeats):\n",
    "        # define network\n",
    "        model = define_model(n_words)\n",
    "        # fit network\n",
    "        model.fit(Xtrain, ytrain, epochs=10, verbose=0)\n",
    "        # evaluate\n",
    "        _, acc = model.evaluate(Xtest, ytest, verbose=0)\n",
    "        scores.append(acc)\n",
    "        print(f\"{i+1} accuracy: {acc}\")\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to evaluate the performance of the 4 different word scoring methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 accuracy: 0.925000011920929\n",
      "2 accuracy: 0.9399999976158142\n",
      "3 accuracy: 0.9350000023841858\n",
      "4 accuracy: 0.9300000071525574\n",
      "1 accuracy: 0.8849999904632568\n",
      "2 accuracy: 0.8899999856948853\n",
      "3 accuracy: 0.9100000262260437\n",
      "4 accuracy: 0.8899999856948853\n",
      "1 accuracy: 0.8700000047683716\n",
      "2 accuracy: 0.8650000095367432\n",
      "3 accuracy: 0.8849999904632568\n",
      "4 accuracy: 0.8500000238418579\n",
      "1 accuracy: 0.7200000286102295\n",
      "2 accuracy: 0.8700000047683716\n",
      "3 accuracy: 0.8650000095367432\n",
      "4 accuracy: 0.8700000047683716\n"
     ]
    }
   ],
   "source": [
    "# run experiment\n",
    "modes = ['binary', 'count', 'tfidf', 'freq']\n",
    "results = DataFrame()\n",
    "for mode in modes:\n",
    "    # prepare data for mode\n",
    "    Xtrain, Xtest = prepare_data(train_docs, test_docs, mode)\n",
    "    # evaluate model on data for mode\n",
    "    results[mode] = evaluate_mode(Xtrain, ytrain, Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         binary     count     tfidf      freq\n",
      "count  4.000000  4.000000  4.000000  4.000000\n",
      "mean   0.932500  0.893750  0.867500  0.831250\n",
      "std    0.006455  0.011087  0.014434  0.074204\n",
      "min    0.925000  0.885000  0.850000  0.720000\n",
      "25%    0.928750  0.888750  0.861250  0.828750\n",
      "50%    0.932500  0.890000  0.867500  0.867500\n",
      "75%    0.936250  0.895000  0.873750  0.870000\n",
      "max    0.940000  0.910000  0.885000  0.870000\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "print(results.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of the run, summary statistics for each word scoring method are provided, summarizing the distribution of model skill scores across each of the 10 runs per mode. We can see that the mean score of both the `count` and `binary` methods appear to be better than `freq` and `tfidf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot results\n",
    "results.boxplot()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A box and whisker plot of the results is also presented, summarizing the accuracy distributions\n",
    "per configuration. We can see that binary achieved the best results with a modest spread and\n",
    "might be the preferred approach for this dataset.\n",
    "\n",
    "The complete example can be found in `7_compare_encodings.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Sentiment for New Reviews\n",
    "Finally,we can develop and use a final model to make predictions for new textual reviews. This is why we wanted the model in the first place. First, we will train a final model on all of the available data. We will use the `binary` mode for scoring the bag-of-words model that was shown to give the best results in the previous section.\n",
    "\n",
    "Predicting the sentiment of new reviews involves following the same steps used to prepare the test data. Specifically, loading the text, cleaning the document, filtering tokens by the chosen vocabulary, converting the remaining tokens to a line, encoding it using the `Tokenizer`, and making a prediction. We can make a prediction of a class value directly with the fit model by calling `predict()` that will return 0 for a negative review and 1 for a positive review. All of these steps can be put into a new function called `predict_sentiment()` that requires the review text, the vocabulary, the tokenizer, and the fit model and returns the predicted sentiment and an associated percentage or confidence-like output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify a review as negative or positive\n",
    "def predict_sentiment(review, vocab, tokenizer, model):\n",
    "    # clean\n",
    "    tokens = clean_doc(review)\n",
    "    # filter by vocab\n",
    "    tokens = [w for w in tokens if w in vocab]\n",
    "    # convert to line\n",
    "    line = ' '.join(tokens)\n",
    "    # encode\n",
    "    encoded = tokenizer.texts_to_matrix([line], mode='binary')\n",
    "    # predict sentiment\n",
    "    yhat = model.predict(encoded, verbose=0)\n",
    "    # retrieve predicted percentage and label\n",
    "    percent_pos = yhat[0, 0]\n",
    "    if round(percent_pos) == 0:\n",
    "        return (1 - percent_pos), 'NEGATIVE'\n",
    "    return percent_pos, 'POSITIVE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now make predictions for new review texts. Below is an example with both a clearly positive and a clearly negative review using the simple MLP developed above with the frequency word scoring mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "57/57 - 0s - loss: 0.4722 - accuracy: 0.7839\n",
      "Epoch 2/10\n",
      "57/57 - 0s - loss: 0.0594 - accuracy: 0.9961\n",
      "Epoch 3/10\n",
      "57/57 - 0s - loss: 0.0165 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "57/57 - 0s - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "57/57 - 0s - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "57/57 - 0s - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "57/57 - 0s - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "57/57 - 0s - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "57/57 - 0s - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "57/57 - 0s - loss: 0.0011 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24f108b7c48>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain = tokenizer.texts_to_matrix(train_docs, mode='binary')\n",
    "Xtest = tokenizer.texts_to_matrix(test_docs, mode='binary')\n",
    "# define network\n",
    "n_words = Xtrain.shape[1]\n",
    "model = define_model(n_words)\n",
    "# fit network\n",
    "model.fit(Xtrain, ytrain, epochs=10, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: [Best movie ever! It was great, I recommend it.]\n",
      "Sentiment: POSITIVE (57.723%)\n",
      "Review: [This is a bad movie.]\n",
      "Sentiment: NEGATIVE (63.711%)\n"
     ]
    }
   ],
   "source": [
    "# test positive text\n",
    "text = 'Best movie ever! It was great, I recommend it.'\n",
    "percent, sentiment = predict_sentiment(text, vocab, tokenizer, model)\n",
    "print(f\"Review: [{text}]\\nSentiment: {sentiment} ({percent * 100:.3f}%)\")\n",
    "# test negative text\n",
    "text = 'This is a bad movie.'\n",
    "percent, sentiment = predict_sentiment(text, vocab, tokenizer, model)\n",
    "print(f\"Review: [{text}]\\nSentiment: {sentiment} ({percent * 100:.3f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The complete example can be found in `8_prediction.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
